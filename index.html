<!DOCTYPE html>
<html lang="en">
<head>

  <title>Jahanzeb Maqbool Hashmi</title>

  <meta name="author" content="Jahanzeb Hashmi">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="./files/stylesheet.css">
  <!--<link rel="icon" type="image/png" href="https://hanruiwang.me/assets/images/mit.ico"> -->

  <meta name="viewport" content="width=device-width, initial-scale=1">


<style>
body {
  margin: 0;
  font-family: Arial, sans-serif;
}

.top-container {
  background-color: #f1f1f1;
  padding: 0px;
  text-align: center;
}

.left {
    float: left;
    width: 170px;
    margin: auto;
}

.header {
  padding: 1px 16px;
  background: #555;
  color: #f1f1f1;
}

.content {
  font-size: xx-small;
  padding: 16px;
}

.sticky {
  position: fixed;
  top: 0;
  width: 100%;
}

.sticky + .content {
  padding-top: 102px;
}
</style>

<!-- <script type="text/javascript" src="./files/jquery-1.12.4.min.js.download"></script> -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Q99V36MX5N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Q99V36MX5N');
</script>

</head>


<body>

<div class="header" id="myHeader">

  <h3> Jahanzeb Maqbool Hashmi </h3>
</div>


<script>
window.onscroll = function() {myFunction()};

var header = document.getElementById("myHeader");
var sticky = header.offsetTop;

function myFunction() {
  if (window.pageYOffset > sticky) {
    header.classList.add("sticky");
  } else {
    header.classList.remove("sticky");
  }
}
</script>



  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <tr style="padding:0px">
  <td style="padding:0px">
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"> 
		
	<tbody>
          <tr style="padding:0px">

            <td style="padding:2.5%;width:40%;max-width:40%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="./files/photo.jpeg" class="hoverZoomLink">
			 
            </td>
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jahanzeb Maqbool Hashmi</name> <br>
                <font face="courier">hashmi.29 AT osu.edu </font>
              </p>
              
			  <p style="text-align:center">
                <a href="files/Resume_Jahanzeb.pdf" target="_blank" rel="noopener noreferrer">Resume</a> &nbsp;/&nbsp;
                <a href="files/CV_Jahanzeb.pdf" target="_blank" rel="noopener noreferrer">CV</a> &nbsp;&nbsp;
              </p>
			  
			  <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=ut1D3NYAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/jahanzeb-hashmi-40aaa712/ target="_blank" rel="noopener noreferrer"">LinkedIn</a> &nbsp;/&nbsp;
				<a href="https://github.com/hashmij" target="_blank" rel="noopener noreferrer">GitHub</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/JM_Hashmi" target="_blank" rel="noopener noreferrer">Twitter</a> &nbsp;&nbsp;
              </p>
              		
				<p>
				I am a Senior Research Engineer at <a href="https://www.osu.edu" target="_blank" rel="noopener noreferrer">The Ohio State University (OSU)</a> where I work at <a href="http://nowlab.cse.ohio-state.edu/" target="_blank" rel="noopener noreferrer">Network Based Computing Laborartory (NBCL)</a>. 
				I work on design and development of scalable software systems that are the backbone of scientific applications and Deep Dearning (DL) frameworks running on multi-petaflop supercomputers (e.g., <a href="https://www.tacc.utexas.edu/systems/frontera" target="_blank" rel="noopener noreferrer">TACC Frontera</a>, <a href="https://www.sdsc.edu/services/hpc/expanse" target="_blank" rel="noopener noreferrer">SDSC Expanse</a>) and HPC Clouds (e.g., <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/hbv2-series" target="_blank" rel="noopener noreferrer">Microsoft Azure</a>). 
				</p>
	
				<p>
				I am leading various projects in the popular high-performance MPI library <a href="http://mvapich.cse.ohio-state.edu/" target="_blank" rel="noopener noreferrer">MVAPICH2</a>. 
				In particular, I am working on optimizing MPI runtime for emerging HPC and cloud systems including optimizations for AMD Rome CPUs, NVIDIA and AMD GPUs, optimized MPI support for Azure HPC cloud. I am also working on designing heirarchical MPI collectives for scaling distribued deep learning, efficient data-movement for sparse data layouts, high-level abstractions for asynchronous offloading, and performance engineering of HPC and Deep Learning workloads on modern HPC systems.
				</p>
<!--				<p>
				I research on developing novel algorithms and optimized software implementations of communication stacks 
				that help applications scale on large-scale HPC and cloud systems. 
				I focus on exploit high-concurrency in modern multi-core and many-core hardware such as CPUs, GPUs, and accelerators and 
				high-throughput networks (e.g., RDMA) to improve the performance of communication libraries.
				</p>
-->
				</td>
				</tr>
	</tbody>
   </table>
   
   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"> 
   <tbody>
          <tr style="padding:0px">
		  <td>
		  </td>
		  <td>


				<p>
				I defended my Ph.D. in Computer Science and Engineering from OSU in May 2020 where I was advised by Prof. <a href="https://web.cse.ohio-state.edu/~panda.2">D. K. Panda</a>. During my Ph.D. research, among other things, I worked on several projects 
				including the design of a shared address space based inter-process communication framework for MPI to achieve truly zero-copy communication operations e.g., point-to-point and collectives (e.g., MPI_Allreduce). 	
				These designs helped in scaling CPU-based data-parallel training on many-core systems like Intel KNL. These designs are released in MVAPICH2 and are still offering orders of magnitude higher performance than the state-of-the-art communication libraries.
				</p>
				
				<p>
				Prior to joining OSU, I did my Masters from Ajou University, South Korea where I worked on energy-efficient High Performance Computing (HPC) using low-powered ARM SoC based cluster applications. I did my B.S from National University of Science and Technology (NUST), Pakistan where I worked on performance characterization and parallelization of numerical simulation codes e.g., particle simulation with SPH methods on multi-core using MPI, OpenMP, and CUDA.
				</p>
				              
              
              
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
			   <li>
				
				June 2020 - A co-authored paper titled "GEMS: GPU Enabled Memory Aware Model Parallelism System for Distributed DNN Training" is accepted to SC'20.
				
				June 2020 - I started working full-time as a Senior Research Associate Engineer at Network Based Computing Laborartory.
				
				May 2020 - I have successfully defended my Ph.D. thesis 
				
				May 2020 -  Our paper titile "FALCON-X: Zero-copy MPI Derived Datatype Processing on Modern CPU and GPU Architectures" is accepted to Journal of Parallel and Distributed Computing (JPDC). Thanks to all the co-authors.
				
				January 2020 - Our paper titled "Machine-agnostic and Communication-aware Designs for MPI on Emerging Architectures" is accepted to IPDPS'20. Thanks to all the co-authors.
				
				May 2019 - I have passed my Ph.D. candidacy exam.
				
				March 2019 - FALCON got nominated for the Best Paper Award at IPDPS'20.
				
				March 2019 - Our paper titled "Design and Characterization of Shared Address Space MPI Collectives on Modern Architectures" is accepted to CCGrid'19. Thanks to all the co-authors.
				
				December 2018 - Our paper titled "FALCON: Efficient Designs for Zero-copy MPI Datatype Processing on Emerging Architectures" is accepted to IPDPS'19. Thanks to all the co-authors.
				
				January 2018 - Our paper titled "Designing Efficient Shared Address Space Reduction Collectives for Multi-/Many-cores" is accepted to IPDPS'18. Thanks to all the co-authors.
						
				
			  </li>
			  </ul>
            </td>
            </tr>
          </tbody>
        </table>


        <heading style="padding: 20px">Publications</heading><a href="https://scholar.google.com/citations?user=ut1D3NYAAAAJ&hl=en">[Full List]</a>
		<div style="padding: 20px">


        </div>
		<table width="100%" align="center" border="0" cellpadding="0">
		<tbody>
			<tr> 
			<td> first pub </td>
			</tr>
		</tbody>
		</table>
  </td>
  </tr>
  </tbody>
  </table>

<hr>


<footer>
    <div class="container">
      <div class="left">
	  

		  
      </div>
    </div>

</footer>





<div class="jvectormap-tip"></div></body></html>

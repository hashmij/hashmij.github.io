<!DOCTYPE html>
<html lang="en">
<head>

  <title>Jahanzeb Maqbool Hashmi Homepage</title>

  <meta name="author" content="Jahanzeb Maqbool Hashmi">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="./files/stylesheet.css">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">


<style>
body {
  margin: 0;
  font-family: Arial, sans-serif;
}

.top-container {
  background-color: #f1f1f1;
  padding: 0px;
  text-align: center;
}

.left {
    float: left;
    width: 170px;
    margin: auto;
}

.header {
  padding: 1px 16px;
  background: #555;
  color: #f1f1f1;
}

.content {
  font-size: xx-small;
  padding: 16px;
}

.sticky {
  position: fixed;
  top: 0;
  width: 100%;
}

.sticky + .content {
  padding-top: 102px;
}
</style>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Q99V36MX5N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Q99V36MX5N');
</script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head>


<body>

<!-- 
-->
<div class="header" id="myHeader">

  <h3><center> Jahanzeb's Homepage</center></h3>
</div>



<script>
window.onscroll = function() {myFunction()};

var header = document.getElementById("myHeader");
var sticky = header.offsetTop;

function myFunction() {
  if (window.pageYOffset > sticky) {
    header.classList.add("sticky");
  } else {
    header.classList.remove("sticky");
  }
}
</script>



  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <tr style="padding:0px">
  <td style="padding:0px">
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"> 
		
	<tbody>
          <tr style="padding:0px">

            <!-- <td style="padding:2.5%;width:40%;max-width:40%"> -->
			<td>
			 <!-- <div style="padding:50px"> -->
			 <div style="padding:70px 50px 50px 50px">  <!-- TOP RIGHT BOTTOM LEFT -->
			 </div>
			 <br>
             <img style="width:90%;max-width:90%" alt="profile photo" src="./files/photo.jpeg" class="hoverZoomLink">

	         <ul style='list-style: none; margin-left: -40px;font-size:20px;'>
				<li style="font-size:16px">
				  <a class="fa fa-github" href="https://github.com/jahanzeb-hashmi">
					<span class="username" style='font-family: Arial'>GitHub</span>
				  </a>
				  /
				  <a class="fa fa-linkedin" href="https://www.linkedin.com/in/jahanzebhashmi/">
					<span class="username" style='font-family: Arial'>LinkedIn</span>
				  </a>
				  /
				  <a class="fa fa-twitter" href="https://twitter.com/JM_Hashmi">
					<span class="username" style='font-family: Arial'>Twitter</span>
				  </a>	
			
				</li>
			</ul>
			  
			 <p> 
<!--				<img style="width:90%;max-width:90%" alt="contact" src="./files/contact.jpeg" class="hoverZoomLink"> 
-->
			 </p>
            </td>
            <td style="padding:2.5%;width:70%;vertical-align:middle">
			<br><br>
              <p style="text-align:center">
                <name>Jahanzeb Maqbool Hashmi</name> 
				<br><br>
                <!-- <font>hashmi [dot] 29 [AT] osu.edu </font> -->
              </p>
              
			  <p style="text-align:center">
                <a href="files/Resume_Jahanzeb.pdf" target="_blank" rel="noopener noreferrer"> <b style="font-size:18px"> Resume </b> </a> &nbsp;/&nbsp;
                <a href="files/CV_Jahanzeb.pdf" target="_blank" rel="noopener noreferrer"> <b style="font-size:18px"> CV </b> </a> &nbsp;/&nbsp;	
				<a href="https://scholar.google.com/citations?user=ut1D3NYAAAAJ&hl=en" target="_blank" rel="noopener noreferrer"> <b style="font-size:18px"> Google Scholar </b></a> 
              </p>
			 
			  
			  <!--
			  <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=ut1D3NYAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/jahanzeb-hashmi-40aaa712/ target="_blank" rel="noopener noreferrer"">LinkedIn</a> &nbsp;/&nbsp;
				<a href="https://github.com/hashmij" target="_blank" rel="noopener noreferrer">GitHub</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/JM_Hashmi" target="_blank" rel="noopener noreferrer">Twitter</a> &nbsp;&nbsp;
              </p>
			  -->
                <p> 	
                    <b style="color:red">I am a Senior Architect (HPC) at NVIDIA where I am working on designing next-generation GPUs, CPUs, and high-speed interconnects as part of the architecture group</b>
                </p>

				<p>
				Previously, I worked as a Senior Research Associate at <a href="https://www.osu.edu" target="_blank" rel="noopener noreferrer">The Ohio State University (OSU)</a> where I worked at <a href="http://nowlab.cse.ohio-state.edu/" target="_blank" rel="noopener noreferrer">Network Based Computing Laboratory (NBCL)</a>. 
<!--
                I worked on design and development of scalable software systems that are the backbone of scientific applications and Deep Learning (DL) frameworks running on multi-petaflop supercomputers (e.g., <a href="https://www.tacc.utexas.edu/systems/frontera" target="_blank" rel="noopener noreferrer">TACC Frontera</a>, <a href="https://www.sdsc.edu/services/hpc/expanse" target="_blank" rel="noopener noreferrer">SDSC Expanse</a>) and HPC Clouds (e.g., <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/hbv2-series" target="_blank" rel="noopener noreferrer">Microsoft Azure</a> and Amazon <a href="https://aws.amazon.com/hpc/parallelcluster/" target="_blank" rel="noopener noreferrer">AWS Parallel Cluster</a>). 


				</p>
				<p>
-->

				I mainly worked on high-performance MPI library <a href="http://mvapich.cse.ohio-state.edu/" target="_blank" rel="noopener noreferrer">MVAPICH2</a> with focus on optimizing MPI runtime for emerging HPC and cloud systems. I primarily led the design and development of GPU-aware MPI library for RDMA networks with AMD/NVIDIA hardware, hierarchical  MPI collectives for scalable scientific and deep learning applications, efficient data-movement for sparse data layouts, high-level abstractions for asynchronous communication offloading, and performance engineering of parallel applications on multi-petaflop supercomputers and cloud systems.
				</p>
<!--				<p>
				I research on developing novel algorithms and optimized software implementations of communication stacks 
				that help applications scale on large-scale HPC and cloud systems. 
				I focus on exploit high-concurrency in modern multi-core and many-core hardware such as CPUs, GPUs, and accelerators and 
				high-throughput networks (e.g., RDMA) to improve the performance of communication libraries.
				</p>
-->
				</td>
				</tr>
	</tbody>
   </table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
            <tr>
			<td>
			</td>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading><b style="color:#6699ff">Service</b></heading>
              <ul>
			  
			  <li>
                  Sep 2021 - I will be serving as member of the Technical Program Committee at IPDPS 2022 (Architecture Track). Please consider submitting your work at <a href=https://www.ipdps.org/> www.ipdps.org </a> <br>
			  </li>		  
			  <li>
				Aug 2021 - I am serving as Technical Reviewer for IEEE MICRO journal <br>
			  </li>		  
			  <li>
				Jun 2021 - I will be serving as Technical Program Committee Member at HOT Interconnects 2021 <br>
			  </li>		  
			  </ul>
            </td>
            </tr>
          </tbody>
        </table>



   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"> 
   <tbody>
          <tr style="padding:0px">
		  <td>
		  </td>
		  <td>

			<heading><b style="color:#6699ff">Education</b></heading>
				<p>
				I completed my Ph.D. in <a href="https://cse.osu.edu/" target="_blank" rel="noopener noreferrer">Computer Science and Engineering</a> from OSU where I was advised by Prof. <a href="https://web.cse.ohio-state.edu/~panda.2 target="_blank" rel="noopener noreferrer">D. K. Panda</a>. 
				Prior to joining OSU, I did my Masters from <a href="https://www.ajou.ac.kr/en" target="_blank" rel="noopener noreferrer">Ajou University</a>, South Korea where I worked on energy-efficient High Performance Computing (HPC) using low-powered ARM SoC based cluster applications. I did my B.S from <a href="https://nust.edu.pk/" target="_blank" rel="noopener noreferrer">National University of Science and Technology (NUST)</a>, Pakistan where I worked on performance characterization and parallelization of numerical simulation codes e.g., particle simulation with SPH methods on multi-core using MPI, OpenMP, and CUDA.
				<!-- During my Ph.D. research, I worked on various projects involving MPI, PGAS, distributed Deep Learning, Task-based models, and performance analysis. I designed a shared address space based inter-process communication framework for MPI to achieve truly zero-copy communication e.g., point-to-point and collectives (e.g., MPI_Allreduce). 
				These designs helped in scaling CPU-based data-parallel training on many-core systems like Intel KNL. These designs are released in MVAPICH2 and are still offering orders of magnitude higher performance than the state-of-the-art communication libraries.
				-->
				
				</p>
	          
            </td>
          </tr>
        </tbody>
	</table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
            <tr>
			<td>
			</td>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading><b style="color:#6699ff">Recent Updates</b></heading>
              <ul>
			  <li>
				Mar 2021 - Co-authored work on designing ROCm-aware MPI library has been accepted to ISC'21 <br>
			  </li>		  
			  
			  <li>
				Mar 2021 - Co-authored work "BluesMPI" has been accepted to ISC'21 <br>
			  </li>		  
			  <li>
				Oct 2020 - Co-authored work "Blink" has been accepted to HiPC'20 <br>
			  </li>		  
			  <li>
				Jun 2020 - Co-authored work "GEMS" has been accepted to SC'20 <br>
			  </li>
			   <li>
				Jun 2020 - I started working full-time as a Senior Research Associate Engineer at <a href="http://nowlab.cse.ohio-state.edu/" target="_blank" rel="noopener noreferrer">NBCL</a> <br>
			  </li>				
			   <li>				
				May 2020 - I have successfully defended my Ph.D. thesis (<a href="files/talks/defense_talk.pdf">Slides</a>) <br>
				</li>
			   <li>				
				May 2020 - "FALCON-X" is accepted to JPDC special issue <br>
			  </li>				
			   <li>				
				Jan 2020 - Our work on efficient MPI topologies for HPC Clouds got accepted to IPDPS'20 <br>
			  </li>				
			   <li>				
				May 2019 - I have passed my Ph.D. candidacy exam (<a href="files/talks/candidacy_talk.pdf">Slides</a>) <br>
			  </li>				
			   <li>				
				Mar 2019 - "FALCON" got nominated for the <b style="color:red">Best Paper Award </b>at IPDPS'19 <br>
			  </li>				
			  <li>				
				Mar 2019 - Our paper on characterizing shared-address-space MPI collectives got accepted to CCGrid'19 <br>
			  </li>	
			  
			  <li>
			    Dec 2018 - Our paper "FALCON" on efficient processing of MPI derived datatypes got accepted to IPDPS'19 <br>
			  </li>
			  
			  <li>				
				Sep 2018 - I presented co-authored paper at Cluster'18 that won <b style="color:red">Best Paper Award</b> <br>
			  </li>
			
			  <li>
				Jul 2018 - Co-authored paper on co-operative rendezvous protocols got nominated for <b style="color:red">Best Paper Award</b> at SC'18
			  </li>
			  
			  <li>
				May 2018 - I presented our shared-address-space MPI runtime work at IPDPS'18 at Vancouver, Canada (<a href="files/talks/ipdps18.pdf">Slides</a>) <br>
			  </li>
			  <li>
			    Apr 2018 - I gave a talk at <a href="https://www.ixpug.org/" target="_blank" rel="noopener noreferrer">IXPUG</a> held at <a href="https://www.kaust.edu.sa/en" target="_blank" rel="noopener noreferrer">KAUST</a>, Saudi Arabia (<a href="files/ixpug-kaust.jpg" target="_blank" rel="noopener noreferrer">Group Photo</a>) (<a href="files/talks/ixpug18-kaust.pdf">Slides</a>)  <br>
			   <li>				
				Dec 2018 - Our paper on sparse non-contigous MPI datatypes (FALCON) is accepted to IPDPS'19 <br>
			   </li>	
			   <li>				
				Jan 2018 - Our work on designing shared-address-space MPI runtime is accepted to IPDPS'18 <br>
			  </li>
			  </ul>
            </td>
            </tr>
          </tbody>
        </table>


        <heading style="padding: 0px"><b style="color:#6699ff">Select Publications</b></heading> 
		<br>
		
		<div style="padding: 10px">

<!--		<p> 
		For complete list of publications, please refer to my <a href="https://scholar.google.com/citations?user=ut1D3NYAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a> page.
		</p>
-->

        </div>

		<table width="100%" align="center" border="0" cellpadding="0">
		<tbody>

			<tr> 
			<td> 

				<papertitle>Blink: Towards Efficient RDMA-based Communication Coroutines for Parallel Python Applications</papertitle>
				<br>
				A. Shafi, <b style="color:#003366">J. Hashmi</b>, H. Subramoni, and DK Panda.
				<br>
				<em>27th IEEE International Conference on High Performance Computing, Data, Analytics and Data Science (HiPC)</em>, 2020.
				<br>
				<br>			
			
				<papertitle>GEMS: GPU Enabled Memory Aware Model Parallelism System for Distributed DNN Training</papertitle>
				<br>
				A. Jain, A. Awan, A. Aljuhani, <b style="color:#003366">J. Hashmi</b>, Q. Anthony, H. Subramoni, D. Panda, R.  Machiraju, A. Parwani
				<br>
				<em>IEEE/ACM International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)</em>, 2020.
				<br>
				<br>			
 
				<papertitle>FALCON-X: Zero-copy MPI Derived Datatype Processing on Modern CPU and GPU Architectures</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, C. Chu, S. Chakraborty, M. Bayatpour, H. Subramoni, and DK Panda.
				<br>
				<em>Journal of Parallel and Distributed Computing (JPDC), Volume 144, October 2020, Pages 1-13, doi.org/10.1016/j.jpdc.2020.05.008</em>, 2020.
				<br>
				<br>			

				<papertitle>Machine-agnostic and Communication-aware Designs for MPI on Emerging Architectures</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, S. Xu, B. Ramesh, M. Bayatpour, H. Subramoni, and D. K. Panda.
				<br>
				<em>34th IEEE International Parallel and Distributed Processing Symposium (IPDPS)</em>, 2020.
				<br>
				<a href="files/talks/ipdps20-short-virtual.pdf">Slides</a> 
				<br>
				<br>			

				<papertitle>FALCON: Efficient Designs for Zero-copy MPI Datatype Processing on Emerging Architectures</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, S. Chakraborty, M. Bayatpour, H. Subramoni, and DK Panda.
				<br>
				<em>33th IEEE International Parallel and Distributed Processing Symposium (IPDPS)</em>, 2019. 
				<br>
				<b style="color:red">Best Paper Finalist</b>
				<br>
				<a href="files/talks/ipdps19.pdf">Slides</a> 
				<br>
				<br>			

				<papertitle>Designing Efficient Shared Address Space Reduction Collectives for Multi-/Many-cores</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, S. Chakraborty, M. Bayatpour, H. Subramoni, and DK Panda.
				<br>
				<em>32th IEEE International Parallel and Distributed Processing Symposium (IPDPS)</em>, 2018.
				<br>
				<a href="files/talks/ipdps18.pdf">Slides</a>
				<br>
				<br>			

				<papertitle>Design and Characterization of Shared Address Space MPI Collectives on Modern Architectures</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, S. Chakraborty, M. Bayatpour, H. Subramoni, and DK Panda.
				<br>
				<em>19th Annual IEEE/ACM International Symposium in Cluster, Cloud, and Grid Computing (CCGrid)</em>, 2019.
				<br>
				<a href="files/talks/ccgrid19.pdf">Slides</a>
				<br>
				<br>		

				<papertitle>Cooperative Rendezvous Protocols for Improved Performance and Overlap</papertitle>
				<br>
				S. Chakraborty, M. Bayatpour, <b style="color:#003366">J. Hashmi</b>, H. Subramoni, and DK Panda.
				<br>
				<em>IEEE/ACM International Conference for High Performance Computing, Networking, Storage, and Analysis (SC)</em>, 2018.
				<br>
				<b style="color:red">Best Paper Finalist</b>
				<br>
				<br>	
				
				<papertitle>SALaR: Scalable and Adaptive Designs for Large Message Reduction Collectives</papertitle>
				<br>
				M. Bayatpour, S. Chakraborty, <b style="color:#003366">J. Hashmi</b>, H. Subramoni, and DK Panda.
				<br>
				<em>IEEE International Conference on Cluster Computing (CLUSTER)</em>, 2018.
				<br>
				<b style="color:red">Best Paper Award</b>
				<br>
				<br>
								
				<papertitle>S-Caffe: Co-designing MPI Runtimes and Caffe for Scalable Deep Learning on Modern GPU Clusters</papertitle>
				<br>
				M. Bayatpour, S. Chakraborty, <b style="color:#003366">J. Hashmi</b>, H. Subramoni, and DK Panda.
				<br>
				<em>22nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programmin (PPoPP)</em>, 2017.
				<br>
				<br>
				
				<papertitle>Kernel-assisted Communication Engine for MPI on Emerging Manycore Processors</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, K. Hamidouche, H. Subramoni, and DK Panda.
				<br>
				<em>24th IEEE International Conference on High Performance Computing, Data, Analytics and Data Science (HiPC)</em>, 2017.
				<br>
				<a href="files/talks/hipc17.pdf">Slides</a>
				<br>
				<br>

				<papertitle>Exploiting and Evaluating OpenSHMEM on KNL Architecture</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, M. Li, H. Subramoni, and DK Panda.
				<br>
				<em>4th Workshop on OpenSHMEM and Related Technologies (OpenSHMEM)</em>, 2017.
				<br>
				<a href="files/talks/oshm17.pdf">Slides</a>
				<br>
				<br>

				<papertitle>Enabling Performance Efficient Runtime Support for Hybrid MPI+UPC++ Programming Models</papertitle>
				<br>
				<b style="color:#003366">J. Hashmi</b>, K. Hamidouche, and DK Panda.
				<br>
				<em>18th IEEE International Conference on High Performance Computing and Communications (HPCC)</em>, 2016.
				<br>
				<a href="files/talks/hpcc16.pdf">Slides</a>
				<br>
				<br>


			</td>			
			
			
			</tr>
		</tbody>
		</table>
  </td>
  </tr>
  </tbody>
  </table>

<hr>


<footer>
<center>
        <h3>Jahanzeb Maqbool Hashmi</h3>
        <ul style='list-style: none; margin-left: -40px;font-size:20px;'>
            <li style="font-size:16px">
              <a class="fa fa-github" href="https://github.com/jahanzeb-hashmi">
                <span class="username" style='font-family: Arial'>GitHub</span>
              </a>
			  &nbsp;/&nbsp;
			  <a class="fa fa-linkedin" href="https://www.linkedin.com/in/jahanzebhashmi/">
                <span class="username" style='font-family: Arial'>LinkedIn</span>
              </a>
			  &nbsp;/&nbsp;
			  <a class="fa fa-twitter" href="https://twitter.com/JM_Hashmi">
                <span class="username" style='font-family: Arial'>Twitter</span>
              </a>			  
            </li>
          </ul>
		  
</center>
</footer>





<div class="jvectormap-tip"></div></body></html>
